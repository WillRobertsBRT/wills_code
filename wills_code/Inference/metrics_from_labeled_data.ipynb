{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import skimage\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Interactive/Widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.core.display import display, HTML\n",
    "import itertools\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import qgrid\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import wandb\n",
    "\n",
    "# Devkit\n",
    "import brtdevkit\n",
    "from brtdevkit.core.db import DBConnector\n",
    "from brtdevkit.core.db.db_filters import *  # We need this for pre-defined filters, e.g., ProjectFilter, DatetimeFilter\n",
    "\n",
    "# Dl-Core\n",
    "import brtdl.metrics\n",
    "from brtdl.metrics.evaluate_metrics import evaluate_metrics\n",
    "from brtdl.data import canonical_types, SampleKeys\n",
    "from brtdl.data.dataset import PathDataset, PredictionDataset\n",
    "from brtdl.data.loaders import im_reader, npy_reader\n",
    "from brtdl import inference, default_arguments\n",
    "from brtdl.transforms import SegmentationTransform\n",
    "from brtdl.visual import colorize_segmentation\n",
    "\n",
    "from divyas_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58155\n"
     ]
    }
   ],
   "source": [
    "# select Images to Evaluate in DataFrame \n",
    "\n",
    "db = DBConnector()\n",
    "\n",
    "# Date filters\n",
    "start_date =datetime(2020, 3, 1)\n",
    "end_date =datetime(2020, 9, 1)\n",
    "\n",
    "# Crop name filter, if needed\n",
    "crop_name = 'SOYBEANS'\n",
    "\n",
    "img_filters = [\n",
    "    {\n",
    "        'project_name': 'shasta',\n",
    "        \"crop_name\": 'COTTON',\n",
    "        'artifacts': {\"$elemMatch\": {'s3_bucket': {\"$exists\": True}, 's3_key': {\"$exists\": True}}},\n",
    "        \"annotations\": {\"$elemMatch\": {\"is_active_version\": True, \"state\": \"ok\", \"kind\": {\"$nin\": [\"ndvi_mask\", \"machine\"]}, \"style\": 'pixelwise', 's3_bucket': {\"$exists\": True}, 's3_key': {\"$exists\": True},  'label_map': {'$in': [{'1': 'crop', '2': 'weed'}, {'1': 'weed', '2': 'crop'}]}}},\n",
    "    }, \n",
    "    DatetimeFilter(key='collected_on', start=start_date, end=end_date)\n",
    "]\n",
    "df = db.get_documents_df('image', img_filters, limit=None)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a dataframe of length:  296\n"
     ]
    }
   ],
   "source": [
    "air = pd.read_csv('ai_rev_cotton_four_images.csv')\n",
    "adf = df[df['_id'].isin(air['nrg_id'])]\n",
    "\n",
    "print(\"I have a dataframe of length: \", len(adf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"operating_field_name\", y=\"fscore\", hue=\"model\", data=means, palette =pal)\n",
    "plt.title('Mean Gridmetric Instance F1 Score')\n",
    "plt.savefig('br_by_field_fscore.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to download inputs and run inference\n",
    "          \n",
    "def download_assets(directory, df):\n",
    "    \"\"\"\n",
    "    Downloads s3 assets of a given list\n",
    "    Args:\n",
    "        directory (Path): the path that the assets will be saved to\n",
    "        assets (iter(dict)): an iterable containing metadata objects that have s3 assets.\n",
    "        Will usually be a dataframe column (ex: `image_df['artifacts'].explode()`)\n",
    "    \"\"\"\n",
    "    s3_client = brt_s3.S3()\n",
    "\n",
    "    def _download(asset, filepath):\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        return s3_client.download_file(asset['s3_bucket'], asset['s3_key'], str(filepath))\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        datapoint_id = str(row['_id'])\n",
    "        try:\n",
    "            annotation = [a for a in row['annotations'] if a['is_active_version'] and a['kind'] != \"ndvi_mask\" and a['style'] == 'pixelwise'][0]\n",
    "        except:\n",
    "            annotation = [a for a in row['annotations'] if a['kind'] in ['f8', 'labelbox', 'brt', 'dataloop']][0]\n",
    "\n",
    "        artifact = [a for a in row['artifacts'] if a['kind'] == 'nrg'][0]\n",
    "        _download(artifact, directory / f'{datapoint_id}_nrg.png')\n",
    "        _download(annotation, directory / f'{datapoint_id}_ann.png')\n",
    "      \n",
    "\n",
    "def download_images(df, artifact_kind, outputdir):\n",
    "    \"\"\"\n",
    "    Helper function to download images from S3 given a dataframe.\n",
    "    :param df: dataframe, expected to be created by a query to brtdevkit\n",
    "    :param artifact_kind: string\n",
    "    :param outputdir: output directory to store the downloaded images\n",
    "    \"\"\"\n",
    "    s3_client = brt_s3.S3()\n",
    "    print(f'Downloading {len(df)} source images...')\n",
    "    for ix, row in df.iterrows():\n",
    "        art = [x for x in row.artifacts if x['kind'] == artifact_kind]\n",
    "        if art:\n",
    "            art = art[0]\n",
    "            fname = os.path.join(outputdir, os.path.basename(art['s3_key']))\n",
    "            s3_client.download_file(art['s3_bucket'], art['s3_key'], fname)\n",
    "    print('Source image download complete')\n",
    "    \n",
    "def download_from_url(url, fname):\n",
    "    \"\"\"\n",
    "    Helper function to download data given an URL\n",
    "    :param url: string, url of the file to be downloaded\n",
    "    :param fname: filename of the downloaded file\n",
    "    \"\"\"\n",
    "    r = requests.get(url, allow_redirects=False)\n",
    "    with open(fname, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=128):\n",
    "            fd.write(chunk)\n",
    "            \n",
    "def run_inference_local(img_dir, model_path, result_dir):\n",
    "    \"\"\"\n",
    "    Use this function if the images and model are already downloaded and locally available.\n",
    "    Inputs: \n",
    "    img_dir: a directory with png images (should be NRG888) to analyze\n",
    "    model_path: the location of the model you want to use\n",
    "    result_dir: a directory to store the finished result images. Does not need to exist already.\n",
    "    \"\"\"\n",
    "        \n",
    "    if os.path.exists(result_dir)==False:\n",
    "        os.mkdir(result_dir)\n",
    "    \n",
    "    channel_order = 'HWC'\n",
    "    batch_size = 1\n",
    "        \n",
    "    resize_shape = (540, 960)#(model_metadata['input_shape'][2], model_metadata['input_shape'][3])\n",
    "    with inference.managed_indir(default_arguments.PathTypes.abspath(img_dir)) as data_dir:\n",
    "        suffix = inference.infer_suffix(data_dir, '')\n",
    "        dset = inference.dset_dispatcher[suffix](data_dir, suffix, resize_shape, channel_order)\n",
    "\n",
    "    # Run inference on downloaded images\n",
    "    pred_gen = inference.predict_jit(dset, default_arguments.PathTypes.abspath(model_path), batch_size, device='cpu')\n",
    "    for img_id, f_hat in pred_gen:\n",
    "        y_hat = np.argmax(f_hat, axis=0).astype(np.ubyte)\n",
    "        img = mpimg.imread(os.path.join(img_dir, img_id + suffix)) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        h, w, c = img.shape\n",
    "        resized_yhat = skimage.transform.resize(y_hat, (h, w), order=0,\n",
    "                                                mode=\"constant\", anti_aliasing=False, \n",
    "                                                preserve_range=True)\n",
    "        resized_yhat = resized_yhat.astype(np.uint8)\n",
    "        colorized_img = colorize_segmentation(img, resized_yhat)\n",
    "        out_path = os.path.join(result_dir, img_id + \".jpg\")\n",
    "        skimage.io.imsave(out_path, colorized_img)\n",
    "        \n",
    "def run_inference_from_web(image_initial, model_names, show_model_metadata=False):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    image_initial: a pandas Dataframe queried from brtdevkit (where you can access the image s3 keys)\n",
    "    model_names: a list containing model names from the soy_models dictionary\n",
    "\n",
    "    Outputs, contained in separate directories:\n",
    "    Downloaded NRG Images\n",
    "    Model downloaded from local file or artifactory url\n",
    "    Results images generated for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Throw an error if the input DF is empty\n",
    "    assert len(image_initial) > 0, 'Input DataFrame is empty. Nothing to analyze.'\n",
    "    \n",
    "    # Throw an error if more than one crop is represented in the DataFrame\n",
    "    assert len(image_initial.crop_name.unique())==1, 'Multiple crop_names in DataFrame'\n",
    "    \n",
    "    today = date.today()\n",
    "    out_name = f'{analysis_name}_{str(today).replace(\"-\", \"_\")}'\n",
    "    # '/home/williamroberts/code/brtdevkit/Projects/Inference Images/0528/CiaramaFazendas_4_SOYBEANS/nrgimages'\n",
    "    out_dir = Path('') / Path(out_name)\n",
    "    if os.path.exists(out_dir):\n",
    "        shutil.rmtree(out_dir)\n",
    "    out_dir.mkdir(parents=False, exist_ok=True)\n",
    "    # Create directories for base images to analyze\n",
    "    img_dir = Path('') / Path(out_name) / Path('nrg_images')\n",
    "    img_dir.mkdir(parents=False, exist_ok=True)\n",
    "    \n",
    "    # Download Images To Infer\n",
    "    download_images(image_initial, 'nrg', img_dir)\n",
    "    \n",
    "    for m in model_names:\n",
    "        model_url = soy_models[m]\n",
    "        model_name = os.path.basename(model_url)\n",
    "        # Create out_dir and model_dir\n",
    "        model_dir = out_dir \n",
    "        model_dir.mkdir(parents=False, exist_ok=True)\n",
    "        result_dir = model_dir / Path(m+'_result_images')\n",
    "        result_dir.mkdir(parents=False, exist_ok=True)\n",
    "        \n",
    "        if show_model_metadata:\n",
    "            model_name = os.path.basename(model_url)\n",
    "            metadata_name = 'metadata.json'\n",
    "            metadata_url = os.path.join(os.path.dirname(model_url), 'metadata.json')\n",
    "            metadata_path = model_dir / Path(metadata_name)\n",
    "            download_from_url(metadata_url, metadata_path)\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                model_metadata = json.load(f)\n",
    "                print(m+' metadata.json:')\n",
    "                print(model_metadata)\n",
    "                print(' ')\n",
    "\n",
    "        # TODO: Will need to change this to be available for multple crop_names, not just soy\n",
    "        # Download model\n",
    "        model_path = model_dir / Path(m + '.jit')\n",
    "        if model_url[0:4] =='http':\n",
    "            download_from_url(model_url, model_path)\n",
    "        else:\n",
    "            model_path = soy_models[m]\n",
    "        run_inference_local(img_dir, model_path, result_dir)\n",
    "        print(f'Inference completed for {m}')\n",
    "\n",
    "def generate_metrics_from_labeled_images(df, model_names):\n",
    "    \"\"\"\n",
    "    Takes a df of annotated images and generates metrics (fscore, precision, recall, etc)\n",
    "    \n",
    "    Inputs: \n",
    "    DatFrame of images with annotations.\n",
    "    Models to use on the evaluation - can be one model or a list of models.\n",
    "    \n",
    "    Outputs:\n",
    "    metrics_df - a well-formatted DatFrame of model evaluation results\n",
    "    \"\"\"\n",
    "    # Set up directories and filepaths for model, images\n",
    "    # i can probably  reuse my code from the multi-model inference functions\n",
    "    model_name = 'allSoy_0'\n",
    "    date = datetime.today().strftime(\"%Y%m%d_%H%M%s\")\n",
    "    out_dir = Path(f'{date}') # This is where all your images/labels will be stored\n",
    "    if os.path.exists(out_dir):\n",
    "        shutil.rmtree(out_dir)\n",
    "    out_dir.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "    model_dir = out_dir / Path('ShastaModel')\n",
    "    model_dir.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "    img_dir = out_dir / Path('Images')\n",
    "    img_dir.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "    preds_dir = out_dir / Path('Preds')\n",
    "    preds_dir.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "    model_url = f'https://artifactory.bluerivertech.com/artifactory/dev-shasta-models/jit/{model_name}/{model_name}.jit'\n",
    "    \n",
    "    # Download Images and Annotations\n",
    "    \n",
    "    \n",
    "    # Generate Metrics\n",
    "    \n",
    "    # Format DataFrame for potting\n",
    "    \n",
    "    return mertics_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set up directories and filepaths for model, images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "means = br.groupby(['operating_field_name' ,'model']).mean().reset_index()\n",
    "\n",
    "pal = ['skyblue', 'olive']\n",
    "\n",
    "plt.figure(figsize=(4, 8))\n",
    "sns.boxplot(data = means, x='model', y='fscore', palette = pal)\n",
    "plt.title('GridMetric Instance F1 Score')\n",
    "plt.savefig('br_allfields_fscore.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics_plots(metrics_df, palette, x, y, hue=None):\n",
    "    \"\"\"\n",
    "    Requires seaborn, matplotlib\n",
    "    Take a dataframe of model evaluation metrics and generate plots\n",
    "    \n",
    "    Inputs: \n",
    "    metrics_df, a Dataframe of model evaluation metrics\n",
    "    palette, a palette of colors to use in the plot\n",
    "    x - The variable to display on the x axis\n",
    "    y - The variable to display on the y axis\n",
    "    hue - If desired, a variable to plot a comparison with\n",
    "    \n",
    "    Outputs:\n",
    "    boxplot - a boxplot of the x- and y-axis variables\n",
    "    barplot - a barplot of the x- and y-axis variables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assert that dataframe is formatted properly\n",
    "    \n",
    "    # generate boxplot and barplot \n",
    "    \n",
    "    return boxplot, barplot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
