{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "\n",
    "import skimage.transform as skt\n",
    "import skimage\n",
    "\n",
    "from random import sample\n",
    "from scipy.special import softmax\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "# brtdevkit\n",
    "import brtdevkit\n",
    "from brtdevkit.core.db import DBConnector\n",
    "from brtdevkit.core.db.db_filters import *  # We need this for pre-defined filters, e.g., ProjectFilter, DatetimeFilter\n",
    "import brtdevkit.util.s3 as brt_s3\n",
    "\n",
    "# dl-core\n",
    "import brtdl.metrics\n",
    "from brtdl.metrics.evaluate_metrics import evaluate_metrics\n",
    "from brtdl import inference, default_arguments\n",
    "from brtdl.data import canonical_types, SampleKeys\n",
    "from brtdl.data.dataset import PathDataset, PredictionDataset\n",
    "from brtdl.data.loaders import im_reader, npy_reader\n",
    "from brtdl.transforms import SegmentationTransform\n",
    "from brtdl.visual import colorize_segmentation\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest models on the 2021 Model Tracking Page: \n",
    "# https://bluerivertechnology.atlassian.net/wiki/spaces/SNS/pages/1865318625/2021+Model+Tracker\n",
    "\n",
    "# Models need to have one output, not the image quality multi-headed outputs (dust, blur, etc)\n",
    "# Can be a locally stored file or url\n",
    "model_paths = {'20210317_1_corn_4':'/home/williamroberts/code/brtdevkit/Projects/Inference Images/models/20210317_1_corn_4.jit',\n",
    "               '20210308_1_soybeans_4' : '/home/williamroberts/code/brtdevkit/Projects/Inference Images/models/20210308_1_soybeans_4.jit',\n",
    "               '20210317_1_cotton_4':  '/home/williamroberts/code/brtdevkit/Projects/Inference Images/models/20210317_1_cotton_4.jit',\n",
    "               '20210220_1_fallow_4' : '/home/williamroberts/code/brtdevkit/Projects/Inference Images/models/20210220_1_fallow_4.jit',\n",
    "               'allSoy_0': '/home/williamroberts/code/brtdevkit/Projects/Inference Images/models/allSoy_0.jit',\n",
    "               '20200528_1_soybeans': 'https://artifactory.bluerivertech.com/artifactory/dev-shashta-models-local/jit/20200528_1_soybeans/20200528_1_soybeans.jit'\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole Lot of Functions to Facilitate Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to download inputs and run inference\n",
    "\n",
    "def download_images(df, artifact_kind, outputdir):\n",
    "    \"\"\"\n",
    "    Helper function to download images from S3 given a dataframe.\n",
    "    :param df: dataframe, expected to be created by a query to brtdevkit\n",
    "    :param artifact_kind: string\n",
    "    :param outputdir: output directory to store the downloaded images\n",
    "    \"\"\"\n",
    "    s3_client = brt_s3.S3()\n",
    "    #print(f'Downloading {len(df)} source images...')\n",
    "    for ix, row in df.iterrows():\n",
    "        art = [x for x in row.artifacts if x['kind'] == artifact_kind]\n",
    "        if art:\n",
    "            art = art[0]\n",
    "            fname = os.path.join(outputdir, os.path.basename(art['s3_key']))\n",
    "            s3_client.download_file(art['s3_bucket'], art['s3_key'], fname)\n",
    "    print('Source image download complete')\n",
    "    \n",
    "def download_from_url(url, fname):\n",
    "    \"\"\"\n",
    "    Helper function to download data given an URL\n",
    "    :param url: string, url of the file to be downloaded\n",
    "    :param fname: filename of the downloaded file\n",
    "    \"\"\"\n",
    "    r = requests.get(url, allow_redirects=False)\n",
    "    with open(fname, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=128):\n",
    "            fd.write(chunk)\n",
    "\n",
    "def get_id_from_s3(df, key):\n",
    "    \"\"\"\n",
    "    Helper function to retrieve an image id given a s3 key.\n",
    "    \"\"\"\n",
    "    found = False\n",
    "    for ix, row in df.iterrows():\n",
    "        art = [x for x in row.artifacts if x['kind'] == 'nrg']\n",
    "        if art:\n",
    "            art = art[0]\n",
    "            #print(art['s3_key'][19:])\n",
    "            if art['s3_key'][19:] == key:\n",
    "                print(row['_id']) \n",
    "                found = True\n",
    "    if found == False:\n",
    "        print('Key not found')\n",
    "            \n",
    "            \n",
    "def run_inference_local(img_dir, model_path, result_dir):\n",
    "    \"\"\"\n",
    "    Use this function if the images and model are already downloaded and locally available.\n",
    "    Inputs: \n",
    "    img_dir: a directory with png images (should be NRG888) to analyze\n",
    "    model_path: the locally stored model you want to use\n",
    "    result_dir: a directory to store the finished result images. Does not need to exist already.\n",
    "    \"\"\"\n",
    "        \n",
    "    if os.path.exists(result_dir)==False:\n",
    "        os.mkdir(result_dir)\n",
    "    \n",
    "    channel_order = 'HWC'\n",
    "    batch_size = 1\n",
    "        \n",
    "    resize_shape = (540, 960)#(model_metadata['input_shape'][2], model_metadata['input_shape'][3])\n",
    "    with inference.managed_indir(default_arguments.PathTypes.abspath(img_dir)) as data_dir:\n",
    "        suffix = inference.infer_suffix(data_dir, '')\n",
    "        dset = inference.dset_dispatcher[suffix](data_dir, suffix, resize_shape, channel_order)\n",
    "\n",
    "    # Run inference on downloaded images\n",
    "    pred_gen = inference.predict_jit(dset, default_arguments.PathTypes.abspath(model_path), batch_size, device='cpu')\n",
    "    try:\n",
    "        for img_id, f_hat in pred_gen:\n",
    "            y_hat = np.argmax(f_hat, axis=0).astype(np.ubyte)\n",
    "            img = mpimg.imread(os.path.join(img_dir, img_id + suffix)) * 255.0\n",
    "            img = img.astype(np.uint8)\n",
    "            h, w, c = img.shape\n",
    "            resized_yhat = skimage.transform.resize(y_hat, (h, w), order=0,\n",
    "                                                    mode=\"constant\", anti_aliasing=False, \n",
    "                                                    preserve_range=True)\n",
    "            resized_yhat = resized_yhat.astype(np.uint8)\n",
    "            colorized_img = colorize_segmentation(img, resized_yhat)\n",
    "            out_path = os.path.join(result_dir, img_id[:36] + \".jpg\")\n",
    "            skimage.io.imsave(out_path, colorized_img)\n",
    "    except:\n",
    "        for img_id, f_hat, heads in pred_gen:\n",
    "            y_hat = np.argmax(f_hat, axis=0).astype(np.ubyte)\n",
    "            img = mpimg.imread(os.path.join(img_dir, img_id + suffix)) * 255.0\n",
    "            img = img.astype(np.uint8)\n",
    "            h, w, c = img.shape\n",
    "            resized_yhat = skimage.transform.resize(y_hat, (h, w), order=0,\n",
    "                                                    mode=\"constant\", anti_aliasing=False, \n",
    "                                                    preserve_range=True)\n",
    "            resized_yhat = resized_yhat.astype(np.uint8)\n",
    "            colorized_img = colorize_segmentation(img, resized_yhat)\n",
    "            out_path = os.path.join(result_dir, img_id[:36] + \".jpg\")\n",
    "            skimage.io.imsave(out_path, colorized_img)\n",
    "        \n",
    "def return_prediction(img_dir, model_path):\n",
    "    \"\"\"\n",
    "    Use this function to run inference and return just the prediciton for a comparison.\n",
    "    Inputs: \n",
    "    img_dir: a directory with png images (should be NRG888) to analyze\n",
    "    model_path: the location of the model you want to use\n",
    "    \"\"\"\n",
    "    \n",
    "    channel_order = 'HWC'\n",
    "    batch_size = 1\n",
    "        \n",
    "    resize_shape = (540, 960)#(model_metadata['input_shape'][2], model_metadata['input_shape'][3])\n",
    "    with inference.managed_indir(default_arguments.PathTypes.abspath(img_dir)) as data_dir:\n",
    "        suffix = inference.infer_suffix(data_dir, '')\n",
    "        dset = inference.dset_dispatcher[suffix](data_dir, suffix, resize_shape, channel_order)\n",
    "\n",
    "    # Run inference on downloaded images\n",
    "    pred_gen = inference.predict_jit(dset, default_arguments.PathTypes.abspath(model_path), batch_size, device='cpu')\n",
    "    for img_id, f_hat in pred_gen:\n",
    "        y_hat = np.argmax(f_hat, axis=0).astype(np.ubyte)\n",
    "        img = mpimg.imread(os.path.join(img_dir, img_id + suffix)) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        h, w, c = img.shape\n",
    "        resized_yhat = skimage.transform.resize(y_hat, (h, w), order=0,\n",
    "                                                mode=\"constant\", anti_aliasing=False, \n",
    "                                                preserve_range=True)\n",
    "        resized_yhat = resized_yhat.astype(np.uint8)\n",
    "        return resized_yhat\n",
    "        \n",
    "def run_inference_from_web(image_initial, model_names, show_model_metadata=False):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    image_initial: a pandas Dataframe queried from brtdevkit (where you can access the image s3 keys)\n",
    "    model_names: a list containing model names from the soy_models dictionary\n",
    "\n",
    "    Outputs, contained in separate directories:\n",
    "    Downloaded NRG Images\n",
    "    Model downloaded from local file or artifactory url\n",
    "    Results images generated for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Throw an error if the input DF is empty\n",
    "    assert len(image_initial) > 0, 'Input DataFrame is empty. Nothing to analyze.'\n",
    "    \n",
    "    # Throw an error if more than one crop is represented in the DataFrame\n",
    "    assert len(image_initial.crop_name.unique())==1, 'Multiple crop_names in DataFrame'\n",
    "    \n",
    "    today = date.today()\n",
    "    out_name = f'{analysis_name}_{str(today).replace(\"-\", \"_\")}'\n",
    "    # '/home/williamroberts/code/brtdevkit/Projects/Inference Images/0528/CiaramaFazendas_4_SOYBEANS/nrgimages'\n",
    "    out_dir = Path('') / Path(out_name)\n",
    "    if os.path.exists(out_dir):\n",
    "        shutil.rmtree(out_dir)\n",
    "    out_dir.mkdir(parents=False, exist_ok=True)\n",
    "    # Create directories for base images to analyze\n",
    "    img_dir = Path('') / Path(out_name) / Path('nrg_images')\n",
    "    img_dir.mkdir(parents=False, exist_ok=True)\n",
    "    \n",
    "    # Download Images To Infer\n",
    "    download_images(image_initial, 'nrg', img_dir)\n",
    "    \n",
    "    for m in model_names:\n",
    "        model_url = soy_models[m]\n",
    "        model_name = os.path.basename(model_url)\n",
    "        # Create out_dir and model_dir\n",
    "        model_dir = out_dir \n",
    "        model_dir.mkdir(parents=False, exist_ok=True)\n",
    "        result_dir = model_dir / Path(m+'_result_images')\n",
    "        result_dir.mkdir(parents=False, exist_ok=True)\n",
    "        \n",
    "        if show_model_metadata:\n",
    "            model_name = os.path.basename(model_url)\n",
    "            metadata_name = 'metadata.json'\n",
    "            metadata_url = os.path.join(os.path.dirname(model_url), 'metadata.json')\n",
    "            metadata_path = model_dir / Path(metadata_name)\n",
    "            download_from_url(metadata_url, metadata_path)\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                model_metadata = json.load(f)\n",
    "                print(m+' metadata.json:')\n",
    "                print(model_metadata)\n",
    "                print(' ')\n",
    "\n",
    "        # TODO: Will need to change this to be available for multple crop_names, not just soy\n",
    "        # Download model\n",
    "        model_path = model_dir / Path(m + '.jit')\n",
    "        if model_url[0:4] =='http':\n",
    "            download_from_url(model_url, model_path)\n",
    "        else:\n",
    "            model_path = soy_models[m]\n",
    "        run_inference_local(img_dir, model_path, result_dir)\n",
    "        print(f'Inference completed for {m}')\n",
    "\n",
    "def softmax_inference_local(img_dir, model_path, result_dir, threshold):\n",
    "    \"\"\"\n",
    "    Use this function if the images and model are already downloaded and locally available.\n",
    "    Inputs: \n",
    "    img_dir: a directory with png images (should be NRG888) to analyze\n",
    "    model_path: the location of the model you want to use\n",
    "    result_dir: a directory to store the finished result images. Does not need to exist already.\n",
    "    \n",
    "    TESTED: Works great!\n",
    "    \"\"\"\n",
    "        \n",
    "    if os.path.exists(result_dir)==False:\n",
    "        os.mkdir(result_dir)\n",
    "    \n",
    "    channel_order = 'HWC'\n",
    "    batch_size = 1\n",
    "        \n",
    "    resize_shape = (540, 960)#(model_metadata['input_shape'][2], model_metadata['input_shape'][3])\n",
    "    with inference.managed_indir(default_arguments.PathTypes.abspath(img_dir)) as data_dir:\n",
    "        suffix = inference.infer_suffix(data_dir, '')\n",
    "        dset = inference.dset_dispatcher[suffix](data_dir, suffix, resize_shape, channel_order)\n",
    "\n",
    "    # Run inference on downloaded images\n",
    "    pred_gen = inference.predict_jit(dset, default_arguments.PathTypes.abspath(model_path), batch_size, device='cpu')\n",
    "    for img_id, f_hat, heads in pred_gen:\n",
    "        x = softmax(f_hat, axis=0)\n",
    "        y_hat = np.greater(x[2, :, :], x[0, :, :]) * 2\n",
    "        y_hat[x[1, :, :] > threshold] = 1\n",
    "        y_hat = y_hat.astype(np.ubyte)\n",
    "        img = mpimg.imread(os.path.join(img_dir, img_id + suffix)) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        h, w, c = img.shape\n",
    "        resized_yhat = skimage.transform.resize(y_hat, (h, w), order=0,\n",
    "                                                mode=\"constant\", anti_aliasing=False, \n",
    "                                                preserve_range=True)\n",
    "        resized_yhat = resized_yhat.astype(np.uint8)\n",
    "        colorized_img = colorize_segmentation(img, resized_yhat)\n",
    "        out_path = os.path.join(result_dir, img_id + \".jpg\")\n",
    "        skimage.io.imsave(out_path, colorized_img)\n",
    "        \n",
    "def generate_evaluations(base_dir, fields, n_images = 50):\n",
    "    \"\"\"\n",
    "    Model names and analysis name should be set up in the previous cell.\n",
    "    Input is list of grower_farm_field names to run inference on and store results\n",
    "    \"\"\"\n",
    "    # assign models by crop\n",
    "    for f in fields:\n",
    "        field_df = full_df[full_df['grower_farm_field']==f]\n",
    "        if field_df.crop_name.unique()[0] == 'CORN':\n",
    "            model = corn_model \n",
    "        elif field_df.crop_name.unique()[0] == 'SOYBEANS':\n",
    "            model = soy_model\n",
    "        elif field_df.crop_name.unique()[0] == 'COTTON':\n",
    "            model = cotton_model\n",
    "        elif field_df.crop_name.unique()[0] == 'NONE_FALLOW_PRE_EMERGE':\n",
    "            model = fallow_model\n",
    "        elif field_df.crop_name.unique()[0] == 'OTHER':\n",
    "            model = fallow_model\n",
    "        else:\n",
    "            print(f'Unrecognized crop in {f}')\n",
    "            break\n",
    "\n",
    "        # Create directories for analysis, images\n",
    "        if os.path.exists(base_dir + analysis_name)==False:\n",
    "            os.mkdir(base_dir + analysis_name)\n",
    "        \n",
    "        analysis_dir = base_dir + analysis_name + '/' + str(f)\n",
    "        nrg_dir = analysis_dir + '/nrg_images'\n",
    "        \n",
    "        if os.path.exists(analysis_dir)==False:\n",
    "            os.mkdir(analysis_dir)\n",
    "        if os.path.exists(nrg_dir)==False:\n",
    "            os.mkdir(nrg_dir)\n",
    "        elif os.path.exists(nrg_dir)==True:\n",
    "            shutil.rmtree(nrg_dir)\n",
    "            os.mkdir(nrg_dir)\n",
    "\n",
    "        model_path = model_paths[model]\n",
    "        \n",
    "        # Choose images and download\n",
    "        image_sample = sample(field_df._id.to_list(), n_images)\n",
    "        sparse = field_df[field_df['_id'].isin(image_sample)]\n",
    "        download_images(sparse, 'nrg', nrg_dir)\n",
    "\n",
    "        # create directory for results\n",
    "        results_dir = analysis_dir + '/' + str(model) + '_results'\n",
    "\n",
    "        # Save results in the result dir\n",
    "        run_inference_local(nrg_dir, model_path, results_dir)\n",
    "        print(f'Finished with {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queried 87870 images in 43.45 s.\n"
     ]
    }
   ],
   "source": [
    "# Query dataframe of fields to evaluate\n",
    "\n",
    "def get_shasta_data(filters={}, start=None, end=None, limit=None):\n",
    "    \"\"\"\n",
    "    Query relevant Shasta data for calculations. \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    connector = DBConnector()\n",
    "    img_filters = {'project_name': 'shasta', **filters}\n",
    "    if start is not None or end is not None:\n",
    "        img_filters = [img_filters, DatetimeFilter(key=\"collected_on\", start=start, end=end)]\n",
    "    df = connector.get_documents_df('image', img_filters, limit=limit)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return df, elapsed_time\n",
    "\n",
    "# Set start and end dates for query\n",
    "start = datetime(2021, 4, 12)\n",
    "end = datetime(2021, 5,31)\n",
    "\n",
    "# Lists of DCMs and Machines\n",
    "dcms = ['DCM-MANATEE', 'DCM-WALRUS', 'DCM-SEAL', 'DCM-OTTER', 'DCM-PORPOISE', 'DCM-DOLPHIN']\n",
    "dcms_2021 = ['DCM11', 'DCM12', 'DCM13', 'DCM14', 'DCM16']\n",
    "machines = [\"SHASTA-FB-BRADLEY\",\"SHASTA-FB-PALADIN\", \"BLACKBIRD\", 'ATM-DUCKDUCK', 'ATM-GOOSE']\n",
    "valid_isp_versions = ['07080203','07090000','07090100']\n",
    "\n",
    "# Select filters\n",
    "filters = { \"artifacts.kind\": \"nrg\",  \n",
    "           'robot_name' : {'$in':dcms_2021}\n",
    "          }\n",
    "\n",
    "full_df, elapsed_time = get_shasta_data(filters=filters, start = start, end = end)\n",
    "full_df['date_collected'] = pd.to_datetime(full_df['collected_on']).dt.date\n",
    "full_df['grower_farm_field'] = full_df['grower'] +'_' + full_df['farm'] + '_' + full_df['operating_field_name']\n",
    "print(f\"Queried {len(full_df)} images in {elapsed_time:.2f} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be stored in: Early_MAY_2021_05_07\n"
     ]
    }
   ],
   "source": [
    "# Choose a name for your analysis\n",
    "analysis_name = 'Early_MAY'\n",
    "today = date.today()\n",
    "analysis_name = f'{analysis_name}_{str(today).replace(\"-\", \"_\")}'\n",
    "print('Results will be stored in:', analysis_name)\n",
    "\n",
    "# models to use in inference\n",
    "corn_model = '20210317_1_corn_4'\n",
    "soy_model = '20210308_1_soybeans_4'\n",
    "cotton_model = '20210317_1_cotton_4'\n",
    "fallow_model = '20210220_1_fallow_4'\n",
    "\n",
    "base_dir = '/home/williamroberts/code/brtdevkit/Projects/Inference Images/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate inference and save locally\n",
    "\n",
    "generate_evaluations(base_dir=base_dir,  fields = full_df.grower_farm_field.unique(),n_images = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
